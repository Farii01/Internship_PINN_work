{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farii01/Internship_PINN_work/blob/main/Senstivity_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://gricad-gitlab.univ-grenoble-alpes.fr/claveaur/pygeotools.git"
      ],
      "metadata": {
        "id": "Hpfe50k-XD50"
      },
      "id": "Hpfe50k-XD50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c822be9",
      "metadata": {
        "id": "4c822be9"
      },
      "outputs": [],
      "source": [
        "import pygeotools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6397c23f",
      "metadata": {
        "id": "6397c23f"
      },
      "source": [
        "### Retrieving the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad2abff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aad2abff",
        "outputId": "6fa1c731-9375-4e54-8388-56359e2ac58c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygeotools was initialized with `verbose=True`.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "model_path = \"/content/COVOBS-x2_400reals.hdf5\"\n",
        "\n",
        "pygeo = pygeotools.pygeotools()\n",
        "model_name=  \"COVOBS-x2_400reals.hdf5\"\n",
        "pygeo.loadModel(\n",
        "    modelName=\"COVOBS-x2_400reals.hdf5\",\n",
        "    modelType=\"covobs_hdf5\",\n",
        "    modelPath=model_path\n",
        ")\n",
        "\n",
        "pygeo.isLoaded(\"COVOBS-x2_400reals.hdf5\")  # Should return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c703ff4",
      "metadata": {
        "id": "9c703ff4"
      },
      "outputs": [],
      "source": [
        "# Setting the grid\n",
        "pygeo.setGrid(\"1deg\")\n",
        "\n",
        "# Creating the context\n",
        "context = {\n",
        "    \"lmax\": 13,\n",
        "    \"r\": pygeo.constants[\"rCore\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbefdba0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbefdba0",
        "outputId": "6d25fd96-302f-4cf7-f6f9-79e74837fb51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ],
      "source": [
        "# Computing the MF and SV\n",
        "MF = pygeo.addMeasure(\"COVOBS-x2_400reals.hdf5\", \"MF\", context)\n",
        "SV = pygeo.addMeasure(\"COVOBS-x2_400reals.hdf5\", \"SV\", context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec93eb1b",
      "metadata": {
        "id": "ec93eb1b"
      },
      "outputs": [],
      "source": [
        "# Retrieving the grid\n",
        "_, (thetas, phis) = pygeo.getCurrentGrid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b6f158c",
      "metadata": {
        "id": "3b6f158c"
      },
      "outputs": [],
      "source": [
        "# Selecting the data\n",
        "Br = pygeo.selectFromMeasure(\"COVOBS-x2_400reals.hdf5\", MF, options={\"component\": \"r\", \"time\": 2020})\n",
        "dBrdt = pygeo.selectFromMeasure(\"COVOBS-x2_400reals.hdf5\", SV, options={\"component\": \"r\", \"time\": 2020})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7b4d677",
      "metadata": {
        "id": "f7b4d677"
      },
      "source": [
        "### Defining the NN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20a3a9e",
      "metadata": {
        "id": "d20a3a9e"
      },
      "outputs": [],
      "source": [
        "node_inputs = 2\n",
        "node_outputs = 2\n",
        "node_layer = 64\n",
        "hidden_layers = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "120de866",
      "metadata": {
        "id": "120de866"
      },
      "outputs": [],
      "source": [
        "#  Defining the NN\n",
        "# For now, it has one hidden layer with 32 nodes\n",
        "# The activation functions are TANH\n",
        "class CoreFlowPINN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CoreFlowPINN, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        layers.append(nn.Linear(node_inputs, node_layer))\n",
        "        layers.append(nn.Tanh())\n",
        "\n",
        "        for _ in range(hidden_layers):\n",
        "            layers.append(nn.Linear(node_layer, node_layer))\n",
        "            layers.append(nn.Tanh())\n",
        "\n",
        "        layers.append(nn.Linear(node_layer, node_outputs))\n",
        "\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = torch.tensor(pygeo.constants[\"rCore\"]) # placing ourselves at the CMB\n",
        "\n",
        "def compute_loss(model, inputs, thetas_nn, phis_nn, Br_nn, dBrdt_nn, dBrdth_nn, dBrdph_nn, r, λ=10):\n",
        "    # Retrieving the predicted flow\n",
        "    u_pred = model(inputs)\n",
        "\n",
        "    # Retrieving the toroidal and poloidal components\n",
        "    T = u_pred[:, 0:1]\n",
        "    S = u_pred[:, 1:2]\n",
        "\n",
        "    # First derivatives of T and S\n",
        "    dT_dth = torch.autograd.grad(T, thetas_nn, grad_outputs=torch.ones_like(T), create_graph=True, retain_graph=True)[0]\n",
        "    dT_dph = torch.autograd.grad(T, phis_nn, grad_outputs=torch.ones_like(T), create_graph=True, retain_graph=True)[0]\n",
        "    dS_dth = torch.autograd.grad(S, thetas_nn, grad_outputs=torch.ones_like(S), create_graph=True, retain_graph=True)[0]\n",
        "    dS_dph = torch.autograd.grad(S, phis_nn, grad_outputs=torch.ones_like(S), create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    sin_th = torch.sin(thetas_nn)\n",
        "    cos_th = torch.cos(thetas_nn)\n",
        "\n",
        "    # Defining u_th and u_ph with T and S\n",
        "    u_th = -dT_dph / sin_th + dS_dth\n",
        "    u_ph = dT_dth + dS_dph / sin_th\n",
        "\n",
        "    # Computing ∇h • Uh\n",
        "    u_th_sin_th = u_th * sin_th\n",
        "    d_u_th_sin_th_dth = torch.autograd.grad(u_th_sin_th, thetas_nn, grad_outputs=torch.ones_like(u_th_sin_th), create_graph=True, retain_graph=True)[0]\n",
        "    d_u_ph_dph = torch.autograd.grad(u_ph, phis_nn, grad_outputs=torch.ones_like(u_ph), create_graph=True, retain_graph=True)[0]\n",
        "    divH_uH = (1 / (r * sin_th)) * (d_u_th_sin_th_dth + d_u_ph_dph)\n",
        "\n",
        "    # Computing ∇h Br\n",
        "    gradH_Br_th = (1 / r) * dBrdth_nn\n",
        "    gradH_Br_ph = (1 / (r * sin_th)) * dBrdph_nn\n",
        "\n",
        "    # Wrapping the induction equation\n",
        "    L1 = dBrdt_nn + Br_nn * divH_uH + u_th * gradH_Br_th + u_ph * gradH_Br_ph\n",
        "    L1_loss = (L1**2).mean()\n",
        "\n",
        "    # Computing L2\n",
        "    L2 = divH_uH * cos_th - u_th * sin_th / r\n",
        "    L2_loss = (L2**2).mean()\n",
        "\n",
        "    # Final loss\n",
        "    Loss = L1_loss + λ * L2_loss\n",
        "\n",
        "    return Loss, L1_loss, L2_loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y3zMxw13XZAL"
      },
      "id": "y3zMxw13XZAL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the loss history\n",
        "loss_history = []\n",
        "\n",
        "# Define patch coordinates and lambda values to explore\n",
        "patches = [\n",
        "    (20, 40, 20, 60),   # Original\n",
        "    (15, 45, 15, 65),   # Larger\n",
        "    (25, 45, 30, 70),   # Shifted\n",
        "]\n",
        "λ_base = 10\n",
        "lambdas = [λ_base / 3, λ_base, λ_base * 3, 10**3, 10**9]  # λ/3, λ, λ×3, 10³, large λ\n",
        "\n",
        "# Grid from pygeo\n",
        "_, (thetas, phis) = pygeo.getCurrentGrid()\n",
        "\n",
        "# Select full Br and dBrdt\n",
        "Br_full = pygeo.selectFromMeasure(\"COVOBS-x2_400reals.hdf5\", MF, options={\"component\": \"r\", \"time\": 2020})\n",
        "dBrdt_full = pygeo.selectFromMeasure(\"COVOBS-x2_400reals.hdf5\", SV, options={\"component\": \"r\", \"time\": 2020})\n",
        "\n",
        "# For collecting results\n",
        "results_summary = []\n",
        "\n",
        "# Outer loop over patches\n",
        "for (i1, i2, j1, j2) in patches:\n",
        "\n",
        "    # Slice thetas/phis and fields\n",
        "    thetas_bis = thetas[i1:i2]\n",
        "    phis_bis = phis[j1:j2]\n",
        "\n",
        "    Br_patch = Br_full[i1:i2, j1:j2, ...]\n",
        "    dBrdt_patch = dBrdt_full[i1:i2, j1:j2, ...]\n",
        "    dBrdth_patch = numpy.gradient(Br_patch, thetas_bis, axis=0)\n",
        "    dBrdph_patch = numpy.gradient(Br_patch, phis_bis, axis=1)\n",
        "\n",
        "    # Grid for this patch\n",
        "    thetas_grid, phis_grid = numpy.meshgrid(thetas_bis, phis_bis, indexing=\"ij\")\n",
        "    thetas_flatten = thetas_grid.flatten()\n",
        "    phis_flatten = phis_grid.flatten()\n",
        "\n",
        "    thetas_nn = torch.tensor(thetas_flatten[:, None], dtype=torch.float32, requires_grad=True)\n",
        "    phis_nn = torch.tensor(phis_flatten[:, None], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "    Br_nn = torch.tensor(Br_patch.flatten()[:, None], dtype=torch.float32)\n",
        "    dBrdt_nn = torch.tensor(dBrdt_patch.flatten()[:, None], dtype=torch.float32)\n",
        "    dBrdth_nn = torch.tensor(dBrdth_patch.flatten()[:, None], dtype=torch.float32)\n",
        "    dBrdph_nn = torch.tensor(dBrdph_patch.flatten()[:, None], dtype=torch.float32)\n",
        "\n",
        "    inputs = torch.cat([thetas_nn, phis_nn], dim=1)\n",
        "\n",
        "    # Inner loop over lambdas\n",
        "    for λ in lambdas:\n",
        "        model = CoreFlowPINN()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
        "\n",
        "        for epoch in range(100):\n",
        "            optimizer.zero_grad()\n",
        "            Loss, L1_loss, L2_loss = compute_loss(\n",
        "                model, inputs, thetas_nn, phis_nn,\n",
        "                Br_nn, dBrdt_nn, dBrdth_nn, dBrdph_nn,\n",
        "                r, λ\n",
        "            )\n",
        "            Loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # After training, compute flow\n",
        "        model.eval()\n",
        "        u_pred = model(inputs)\n",
        "        T = u_pred[:, 0:1]\n",
        "        S = u_pred[:, 1:2]\n",
        "\n",
        "        dT_dth = torch.autograd.grad(T, thetas_nn, grad_outputs=torch.ones_like(T), create_graph=True)[0]\n",
        "        dT_dph = torch.autograd.grad(T, phis_nn, grad_outputs=torch.ones_like(T), create_graph=True)[0]\n",
        "        dS_dth = torch.autograd.grad(S, thetas_nn, grad_outputs=torch.ones_like(S), create_graph=True)[0]\n",
        "        dS_dph = torch.autograd.grad(S, phis_nn, grad_outputs=torch.ones_like(S), create_graph=True)[0]\n",
        "\n",
        "        sin_th = torch.sin(thetas_nn)\n",
        "\n",
        "        u_theta = -dT_dph / sin_th + dS_dth\n",
        "        u_phi = dT_dth + dS_dph / sin_th\n",
        "\n",
        "        # Store result\n",
        "        results_summary.append({\n",
        "            \"patch\": (i1, i2, j1, j2),\n",
        "            \"lambda\": λ,\n",
        "            \"loss\": Loss.item(),\n",
        "            \"loss_L1\": L1_loss.item(),\n",
        "            \"loss_L2\": L2_loss.item(),\n",
        "            \"u_theta\": u_theta.detach(),\n",
        "            \"u_phi\": u_phi.detach()\n",
        "        })\n",
        "\n",
        "print(\"Done\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ddiSEwttmfMf"
      },
      "id": "ddiSEwttmfMf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def print_patchwise_loss_and_flow_differences(results_summary):\n",
        "    by_patch = defaultdict(list)\n",
        "    for entry in results_summary:\n",
        "        by_patch[entry[\"patch\"]].append(entry)\n",
        "\n",
        "    print(\"\\n=== Summary of Losses and Flow Differences ===\")\n",
        "    for patch, entries in by_patch.items():\n",
        "        print(f\"\\nPatch: {patch}\")\n",
        "        sorted_entries = sorted(entries, key=lambda x: x[\"lambda\"])\n",
        "        for e in sorted_entries:\n",
        "            print(f\"  λ = {e['lambda']:10.1e} | Loss = {e['loss']:.6f} | L1 = {e['loss_L1']:.6f} | L2 = {e['loss_L2']:.6f}\")\n",
        "\n",
        "        # Compute flow diffs between every pair\n",
        "        for i in range(len(sorted_entries)):\n",
        "            for j in range(i + 1, len(sorted_entries)):\n",
        "                e1 = sorted_entries[i]\n",
        "                e2 = sorted_entries[j]\n",
        "\n",
        "                u1_th, u1_ph = e1[\"u_theta\"], e1[\"u_phi\"]\n",
        "                u2_th, u2_ph = e2[\"u_theta\"], e2[\"u_phi\"]\n",
        "\n",
        "                delta = torch.norm(u1_th - u2_th) + torch.norm(u1_ph - u2_ph)\n",
        "                ref = torch.norm(u1_th) + torch.norm(u1_ph)\n",
        "                percent = (delta / ref).item() * 100\n",
        "\n",
        "                if percent < 5:\n",
        "                    status = \" Stable\"\n",
        "                elif percent < 15:\n",
        "                    status = \" Moderate\"\n",
        "                else:\n",
        "                    status = \" Unstable\"\n",
        "\n",
        "                print(f\"    → λ={e1['lambda']:.1e} vs λ={e2['lambda']:.1e} → Change: {percent:.2f}% → {status}\")\n",
        "\n",
        "print_patchwise_loss_and_flow_differences(results_summary)\n",
        "\n"
      ],
      "metadata": {
        "id": "3JuPWt2gQY0i",
        "outputId": "009faee1-355d-4274-fc27-811a5ffa5780",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3JuPWt2gQY0i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Summary of Losses and Flow Differences ===\n",
            "\n",
            "Patch: (20, 40, 20, 60)\n",
            "  λ =    3.3e+00 | Loss = 2139899.750000 | L1 = 2139899.750000 | L2 = 0.000065\n",
            "  λ =    1.0e+01 | Loss = 1999347.000000 | L1 = 1999347.000000 | L2 = 0.000049\n",
            "  λ =    3.0e+01 | Loss = 2072402.375000 | L1 = 2072402.375000 | L2 = 0.000056\n",
            "  λ =    1.0e+03 | Loss = 2061399.375000 | L1 = 2061399.375000 | L2 = 0.000055\n",
            "  λ =    1.0e+09 | Loss = 2040402.750000 | L1 = 1996747.000000 | L2 = 0.000044\n",
            "    → λ=3.3e+00 vs λ=1.0e+01 → Change: 17.33% →  Unstable\n",
            "    → λ=3.3e+00 vs λ=3.0e+01 → Change: 14.21% →  Moderate\n",
            "    → λ=3.3e+00 vs λ=1.0e+03 → Change: 9.05% →  Moderate\n",
            "    → λ=3.3e+00 vs λ=1.0e+09 → Change: 15.39% →  Unstable\n",
            "    → λ=1.0e+01 vs λ=3.0e+01 → Change: 6.19% →  Moderate\n",
            "    → λ=1.0e+01 vs λ=1.0e+03 → Change: 9.43% →  Moderate\n",
            "    → λ=1.0e+01 vs λ=1.0e+09 → Change: 3.02% →  Stable\n",
            "    → λ=3.0e+01 vs λ=1.0e+03 → Change: 6.42% →  Moderate\n",
            "    → λ=3.0e+01 vs λ=1.0e+09 → Change: 5.28% →  Moderate\n",
            "    → λ=1.0e+03 vs λ=1.0e+09 → Change: 6.90% →  Moderate\n",
            "\n",
            "Patch: (15, 45, 15, 65)\n",
            "  λ =    3.3e+00 | Loss = 1865373.875000 | L1 = 1865373.875000 | L2 = 0.000020\n",
            "  λ =    1.0e+01 | Loss = 1904911.375000 | L1 = 1904911.375000 | L2 = 0.000044\n",
            "  λ =    3.0e+01 | Loss = 2093600.625000 | L1 = 2093600.625000 | L2 = 0.000050\n",
            "  λ =    1.0e+03 | Loss = 2160196.500000 | L1 = 2160196.500000 | L2 = 0.000052\n",
            "  λ =    1.0e+09 | Loss = 1557056.750000 | L1 = 1535912.250000 | L2 = 0.000021\n",
            "    → λ=3.3e+00 vs λ=1.0e+01 → Change: 43.96% →  Unstable\n",
            "    → λ=3.3e+00 vs λ=3.0e+01 → Change: 57.12% →  Unstable\n",
            "    → λ=3.3e+00 vs λ=1.0e+03 → Change: 56.07% →  Unstable\n",
            "    → λ=3.3e+00 vs λ=1.0e+09 → Change: 14.37% →  Moderate\n",
            "    → λ=1.0e+01 vs λ=3.0e+01 → Change: 15.90% →  Unstable\n",
            "    → λ=1.0e+01 vs λ=1.0e+03 → Change: 14.22% →  Moderate\n",
            "    → λ=1.0e+01 vs λ=1.0e+09 → Change: 41.68% →  Unstable\n",
            "    → λ=3.0e+01 vs λ=1.0e+03 → Change: 4.50% →  Stable\n",
            "    → λ=3.0e+01 vs λ=1.0e+09 → Change: 51.58% →  Unstable\n",
            "    → λ=1.0e+03 vs λ=1.0e+09 → Change: 50.10% →  Unstable\n",
            "\n",
            "Patch: (25, 45, 30, 70)\n",
            "  λ =    3.3e+00 | Loss = 1645971.875000 | L1 = 1645971.875000 | L2 = 0.000154\n",
            "  λ =    1.0e+01 | Loss = 3855316.500000 | L1 = 3855316.500000 | L2 = 0.000032\n",
            "  λ =    3.0e+01 | Loss = 2443896.000000 | L1 = 2443896.000000 | L2 = 0.000142\n",
            "  λ =    1.0e+03 | Loss = 2546210.500000 | L1 = 2546210.500000 | L2 = 0.000099\n",
            "  λ =    1.0e+09 | Loss = 2494528.500000 | L1 = 2446284.000000 | L2 = 0.000048\n",
            "    → λ=3.3e+00 vs λ=1.0e+01 → Change: 37.65% →  Unstable\n",
            "    → λ=3.3e+00 vs λ=3.0e+01 → Change: 12.93% →  Moderate\n",
            "    → λ=3.3e+00 vs λ=1.0e+03 → Change: 23.84% →  Unstable\n",
            "    → λ=3.3e+00 vs λ=1.0e+09 → Change: 27.14% →  Unstable\n",
            "    → λ=1.0e+01 vs λ=3.0e+01 → Change: 49.51% →  Unstable\n",
            "    → λ=1.0e+01 vs λ=1.0e+03 → Change: 30.99% →  Unstable\n",
            "    → λ=1.0e+01 vs λ=1.0e+09 → Change: 16.51% →  Unstable\n",
            "    → λ=3.0e+01 vs λ=1.0e+03 → Change: 32.24% →  Unstable\n",
            "    → λ=3.0e+01 vs λ=1.0e+09 → Change: 33.45% →  Unstable\n",
            "    → λ=1.0e+03 vs λ=1.0e+09 → Change: 18.56% →  Unstable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c2ac2f6",
      "metadata": {
        "id": "1c2ac2f6"
      },
      "source": [
        "### Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83789eb5",
      "metadata": {
        "id": "83789eb5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.loglog(loss_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee32085",
      "metadata": {
        "id": "5ee32085"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdcdc6cf",
      "metadata": {
        "id": "fdcdc6cf"
      },
      "outputs": [],
      "source": [
        "u_th_map = u_th.reshape(Br.shape).detach().numpy()\n",
        "u_ph_map = u_ph.reshape(Br.shape).detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "805ef3f1",
      "metadata": {
        "id": "805ef3f1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cmocean\n",
        "import cartopy.crs as ccrs\n",
        "\n",
        "u_th_full = numpy.zeros((thetas.size, phis.size))\n",
        "u_th_full[i1:i2,j1:j2] = u_th_map\n",
        "\n",
        "thetas_bis_deg = numpy.rad2deg(thetas)\n",
        "phis_bis_deg = numpy.rad2deg(phis)\n",
        "\n",
        "latitudes = pygeo.convertThetasToLatitudes(thetas)\n",
        "longitudes = pygeo.convertPhisToLongitudes(phis)\n",
        "\n",
        "lat_grid, lon_grid = numpy.meshgrid(latitudes, longitudes, indexing=\"ij\")\n",
        "\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "\n",
        "# Set the projection to Hammer and add the axes\n",
        "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Aitoff())\n",
        "\n",
        "u_max = numpy.max(numpy.abs(u_th_full))\n",
        "\n",
        "# Use `pcolormesh` to project the data onto the map\n",
        "pcol = ax.pcolormesh(lon_grid, lat_grid, u_th_full, transform=ccrs.PlateCarree(), cmap=cmocean.cm.balance, vmin=-u_max, vmax=u_max)\n",
        "\n",
        "# Add coastlines for context\n",
        "ax.coastlines()\n",
        "\n",
        "plt.colorbar(pcol)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
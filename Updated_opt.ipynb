{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farii01/Internship_PINN_work/blob/main/Updated_opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WyE0odYT4N5r",
      "metadata": {
        "id": "WyE0odYT4N5r"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://gricad-gitlab.univ-grenoble-alpes.fr/claveaur/pygeotools.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DrYzazJN4Pn6",
      "metadata": {
        "id": "DrYzazJN4Pn6"
      },
      "outputs": [],
      "source": [
        "import pygeotools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53TdxT8P4SBC",
      "metadata": {
        "id": "53TdxT8P4SBC"
      },
      "outputs": [],
      "source": [
        "model_path = \"/content/COVOBS-x2_400reals.hdf5\"\n",
        "\n",
        "pygeo = pygeotools.pygeotools()\n",
        "model_name=  \"COVOBS-x2_400reals.hdf5\"\n",
        "pygeo.loadModel(\n",
        "    modelName=\"COVOBS-x2_400reals.hdf5\",\n",
        "    modelType=\"covobs_hdf5\",\n",
        "    modelPath=model_path\n",
        ")\n",
        "\n",
        "pygeo.isLoaded(\"COVOBS-x2_400reals.hdf5\")  # Should return True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6397c23f",
      "metadata": {
        "id": "6397c23f"
      },
      "source": [
        "### Retrieving the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c703ff4",
      "metadata": {
        "id": "9c703ff4"
      },
      "outputs": [],
      "source": [
        "# Setting the grid\n",
        "pygeo.setGrid(\"1deg\")\n",
        "\n",
        "# Creating the context\n",
        "context = {\n",
        "    \"lmax\": 13,\n",
        "    \"r\": pygeo.constants[\"rCore\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbefdba0",
      "metadata": {
        "id": "cbefdba0"
      },
      "outputs": [],
      "source": [
        "# Computing the MF and SV\n",
        "MF = pygeo.addMeasure(\"COVOBS-x2_400reals.hdf5\", \"MF\", context)\n",
        "SV = pygeo.addMeasure(\"COVOBS-x2_400reals.hdf5\", \"SV\", context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec93eb1b",
      "metadata": {
        "id": "ec93eb1b"
      },
      "outputs": [],
      "source": [
        "# Retrieving the grid\n",
        "_, (thetas, phis) = pygeo.getCurrentGrid()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54866c66",
      "metadata": {
        "id": "54866c66"
      },
      "source": [
        "## Generating the patches for input in PINN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_EhA1-3KFOW_",
      "metadata": {
        "id": "_EhA1-3KFOW_"
      },
      "source": [
        "we cut the Earth into small square patches, train a separate neural network on each patch, then stitch the results together.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a797e596",
      "metadata": {
        "id": "a797e596"
      },
      "outputs": [],
      "source": [
        "def generate_patches(theta_size=20, phi_size=20, overlap=5):# 20 rows longitude, 20 cols latitude\n",
        "    patches = []\n",
        "# without overlap\n",
        "    dtheta = theta_size - overlap\n",
        "    dphi = phi_size - overlap\n",
        "\n",
        "#going from pole to pole (0 to 180 in colatitude) by stepping in 15Â° chunks (because dtheta = 15)\n",
        "    for i1 in range(0, 180 - theta_size + 1, dtheta):\n",
        "        i2 = i1 + theta_size\n",
        "        for j1 in range(0, 360 - phi_size + 1, dphi):\n",
        "            j2 = j1 + phi_size\n",
        "\n",
        "            patches.append((i1, i2, j1, j2))\n",
        "\n",
        "    return patches\n",
        "'''\n",
        "This loop creates a full list of (i1, i2, j1, j2) â€” patches of size 20Â°Ã—20Â°, sliding across the whole globe, overlapping 5Â°.\n",
        "\n",
        "Each patch will be used to train a small PINN, then all will be stitched together into one global map.\n",
        "'''\n",
        "# How to use?\n",
        "patches = generate_patches(theta_size=20, phi_size=20, overlap=5)\n",
        "\n",
        "for i1, i2, j1, j2 in patches:\n",
        "    ... # For each patch, we have to solve the inverse problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b6f158c",
      "metadata": {
        "id": "3b6f158c"
      },
      "outputs": [],
      "source": [
        "# Selecting the data\n",
        "Br = pygeo.selectFromMeasure(\"COVOBS-x2_400reals.hdf5\", MF, options={\"component\": \"r\", \"time\": 2020})\n",
        "dBrdt = pygeo.selectFromMeasure(\"COVOBS-x2_400reals.hdf5\", SV, options={\"component\": \"r\", \"time\": 2020})\n",
        "'''\n",
        "#Take a small patch (20Â° Ã— 20Â°)\n",
        "i1, i2 = 60, 80\n",
        "j1, j2 = 330, 350\n",
        "\n",
        "# Computing the derivative wrt theta and phi of the MF\n",
        "dBrdth = numpy.gradient(Br, thetas, axis=0)[i1:i2,j1:j2,...]\n",
        "dBrdph = numpy.gradient(Br, phis, axis=1)[i1:i2,j1:j2,...]\n",
        "\n",
        "Br = Br[i1:i2,j1:j2,...]\n",
        "dBrdt = dBrdt[i1:i2,j1:j2,...]\n",
        "\n",
        "# Slicing the grid\n",
        "thetas_bis = thetas[i1:i2]\n",
        "phis_bis = phis[j1:j2]\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09e84ad3",
      "metadata": {
        "id": "09e84ad3"
      },
      "source": [
        "### Creating the NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20a3a9e",
      "metadata": {
        "id": "d20a3a9e"
      },
      "outputs": [],
      "source": [
        "node_inputs = 2\n",
        "node_outputs = 2\n",
        "node_layer = 64\n",
        "hidden_layers = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "120de866",
      "metadata": {
        "id": "120de866"
      },
      "outputs": [],
      "source": [
        "#  Defining the NN\n",
        "# For now, it has one hidden layer with 32 nodes\n",
        "# The activation functions are TANH\n",
        "class CoreFlowPINN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CoreFlowPINN, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        layers.append(nn.Linear(node_inputs, node_layer))\n",
        "        layers.append(nn.Tanh())\n",
        "\n",
        "        for _ in range(hidden_layers):\n",
        "            layers.append(nn.Linear(node_layer, node_layer))\n",
        "            layers.append(nn.Tanh())\n",
        "\n",
        "        layers.append(nn.Linear(node_layer, node_outputs))\n",
        "\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cc552a1",
      "metadata": {
        "id": "9cc552a1"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# Shaping everything for the NN\n",
        "\n",
        "# Creating the grid\n",
        "thetas_grid, phis_grid = numpy.meshgrid(thetas_bis, phis_bis, indexing=\"ij\")\n",
        "\n",
        "# Creating the (flatten) grid points\n",
        "thetas_flatten = thetas_grid.flatten()\n",
        "phis_flatten = phis_grid.flatten()\n",
        "\n",
        "# Creating grid tensors to feed the NN\n",
        "thetas_nn = torch.tensor(thetas_flatten[:, None], dtype=torch.float32, requires_grad=True)\n",
        "phis_nn = torch.tensor(phis_flatten[:, None], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# Creating tensors for the MF and SV\n",
        "Br_nn = torch.tensor(Br.flatten()[:, None], dtype=torch.float32)\n",
        "dBrdt_nn = torch.tensor(dBrdt.flatten()[:, None], dtype=torch.float32)\n",
        "dBrdth_nn = torch.tensor(dBrdth.flatten()[:, None], dtype=torch.float32)\n",
        "dBrdph_nn = torch.tensor(dBrdph.flatten()[:, None], dtype=torch.float32)\n",
        "\n",
        "# Ravel the angles\n",
        "inputs = torch.cat([thetas_nn, phis_nn], dim=1)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ONM5SM_4ct37",
      "metadata": {
        "id": "ONM5SM_4ct37"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of patches: {len(patches)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a604454",
      "metadata": {
        "id": "5a604454"
      },
      "source": [
        "### Adding the physics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7189ba3d",
      "metadata": {
        "id": "7189ba3d"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "We want to solve the radial induction equation at the CMB\n",
        "    dBr / dt + âˆ‡h â€¢ (Uh Br) = 0\n",
        "\n",
        "with some quasi-geostrophic condition (meaning the flow will partly align along the axis of rotation, making columns-like flow)\n",
        "    âˆ‡h â€¢ (Uh cos(Î¸)) = 0\n",
        "\n",
        "As the flow is incompressible, it is subject to âˆ‡ â€¢ U = 0. As a result, it admits a unique toroidal-poloidal decomposition:\n",
        "    Uh = âˆ‡ x (r T) + âˆ‡ (r S)\n",
        "\n",
        "Thus, instead of directly predicting uÎ¸ and uÏ†, it appears clever to predict T and S as it already enforces the incompressibility condition.\n",
        "\n",
        "In spherical coordinates, one has\n",
        "    uÎ¸ = -(dT/dÏ†) / sin(Î¸) + dS/dÎ¸\n",
        "    uÏ† = dT/dÎ¸ + (dS/dÏ†) / sin(Î¸)\n",
        "\"\"\"\n",
        "\n",
        "r = torch.tensor(pygeo.constants[\"rCore\"]) # placing ourselves at the CMB\n",
        "\n",
        "def compute_loss(model, inputs, thetas_nn, phis_nn, Br_nn, dBrdt_nn, dBrdth_nn, dBrdph_nn):\n",
        "\n",
        "    # Retrieving the predicted flow\n",
        "    u_pred = model(inputs)\n",
        "\n",
        "    # Retrieving the toroidal and poloidal components\n",
        "\n",
        "    T = u_pred[:, 0:1]\n",
        "    S = u_pred[:, 1:2]\n",
        "\n",
        "    # First derivatives of T and S\n",
        "    dT_dth = torch.autograd.grad(T, thetas_nn, grad_outputs=torch.ones_like(T), create_graph=True, retain_graph=True)[0]\n",
        "    dT_dph = torch.autograd.grad(T, phis_nn, grad_outputs=torch.ones_like(T), create_graph=True, retain_graph=True)[0]\n",
        "    dS_dth = torch.autograd.grad(S, thetas_nn, grad_outputs=torch.ones_like(S), create_graph=True, retain_graph=True)[0]\n",
        "    dS_dph = torch.autograd.grad(S, phis_nn, grad_outputs=torch.ones_like(S), create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    \"\"\"\n",
        "    Computing L1\n",
        "    \"\"\"\n",
        "    # Computing the L1Â² loss function\n",
        "    # L1Â² = || dBr / dt + âˆ‡h â€¢ (Uh Br) ||Â²\n",
        "    # âˆ‡h â€¢ (Uh Br) = (âˆ‡h â€¢ Uh) Br + Uh â€¢ (âˆ‡h Br)\n",
        "\n",
        "    sin_th = torch.sin(thetas_nn)\n",
        "    cos_th = torch.cos(thetas_nn)\n",
        "    tan_th = torch.tan(thetas_nn)\n",
        "\n",
        "    # We are defining u_th and u_ph with T and S\n",
        "    u_th = -dT_dph / sin_th + dS_dth\n",
        "    u_ph = dT_dth + dS_dph / sin_th\n",
        "\n",
        "    # Computing âˆ‡h â€¢ Uh\n",
        "    u_th_sin_th = u_th * sin_th\n",
        "    d_u_th_sin_th_dth = torch.autograd.grad(u_th_sin_th, thetas_nn, grad_outputs=torch.ones_like(u_th_sin_th), create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    d_u_ph_dph = torch.autograd.grad(u_ph, phis_nn, grad_outputs=torch.ones_like(u_ph), create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    divH_uH = (1 / (r * sin_th)) * (d_u_th_sin_th_dth + d_u_ph_dph)\n",
        "    # divH_uH = u_th * tan_th / r\n",
        "\n",
        "    # Computing âˆ‡h Br\n",
        "    # The derivatives are provided as they are not the NN variables but inputs\n",
        "    gradH_Br_th = (1 / r) * dBrdth_nn\n",
        "    gradH_Br_ph = (1 / (r * sin_th)) * dBrdph_nn\n",
        "\n",
        "    # Wrapping the induction equation\n",
        "    L1 = dBrdt_nn + Br_nn * divH_uH + u_th * gradH_Br_th + u_ph * gradH_Br_ph\n",
        "\n",
        "    \"\"\"\n",
        "    Computing L2\n",
        "    \"\"\"\n",
        "    L2 = divH_uH - u_th * tan_th / r\n",
        "\n",
        "    return L1, L2, u_th, u_ph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c42f4fa3",
      "metadata": {
        "id": "c42f4fa3"
      },
      "outputs": [],
      "source": [
        "# I moved everything to the training loop so that for each patch in every iteration, the model receives the correct,\n",
        "# patch-specific input like thetas_nn, phis_nn, Br_nn, dBrdt_nn, dBrdth_nn, dBrdph_nn\n",
        "\n",
        "# Training over all patches\n",
        "num_realizations = 5 # 5 time on each patch\n",
        "epochs = 1000\n",
        "Î» = 500\n",
        "\n",
        "patch_centers=[]\n",
        "\n",
        "\n",
        "print(f\"Number of times each patch will run: {num_realizations}\")\n",
        "print(f\"Number of epochs: {epochs}\")\n",
        "\n",
        "\n",
        "'''\n",
        "# for all patches\n",
        "for i1, i2, j1, j2 in patches:\n",
        "    if i1 < 10 or i2 > 170 or (i1 <= 90 <= i2):\n",
        "        continue  # skip poles and equator\n",
        "\n",
        "'''\n",
        "\n",
        "# for less time consumption, I am using 50 patches\n",
        "test_patches = patches[ :100] # you can slice it if u want less, that is why i created a seperate variable\n",
        "\n",
        "print(f\"Number of patches: {len(patches)} but we will consider : {len(test_patches)}\")\n",
        "\n",
        "for patch_idx, (i1, i2, j1, j2) in enumerate(test_patches, start=1):\n",
        "    # Skip poles and equator patches if needed\n",
        "    if i1 < 10 or i2 > 170 or (i1 <= 90 <= i2):\n",
        "      continue\n",
        "\n",
        "\n",
        "    print(f\"Processing from patch {patch_idx} Since the ones before were either equator or pole\") # To know when it is starting and what is getting out of calculation\n",
        "\n",
        "#slice all Br and inputs\n",
        "    Br_patch = Br[i1:i2, j1:j2, ...]\n",
        "    dBrdt_patch = dBrdt[i1:i2, j1:j2, ...]\n",
        "\n",
        "    #differential or br and sv w.r.t. phi and theta\n",
        "    dBrdth = numpy.gradient(Br, thetas, axis=0)[i1:i2, j1:j2, ...]\n",
        "    dBrdph = numpy.gradient(Br, phis, axis=1)[i1:i2, j1:j2, ...]\n",
        "\n",
        "    thetas_bis = thetas[i1:i2]\n",
        "    phis_bis = phis[j1:j2]\n",
        "\n",
        "    thetas_grid, phis_grid = numpy.meshgrid(thetas_bis, phis_bis, indexing=\"ij\")\n",
        "    thetas_flat = thetas_grid.flatten()\n",
        "    phis_flat = phis_grid.flatten()\n",
        "\n",
        "    thetas_nn = torch.tensor(thetas_flat[:, None], dtype=torch.float32, requires_grad=True)\n",
        "    phis_nn = torch.tensor(phis_flat[:, None], dtype=torch.float32, requires_grad=True)\n",
        "    Br_nn = torch.tensor(Br_patch.flatten()[:, None], dtype=torch.float32)\n",
        "    dBrdt_nn = torch.tensor(dBrdt_patch.flatten()[:, None], dtype=torch.float32)\n",
        "    dBrdth_nn = torch.tensor(dBrdth.flatten()[:, None], dtype=torch.float32)\n",
        "    dBrdph_nn = torch.tensor(dBrdph.flatten()[:, None], dtype=torch.float32)\n",
        "\n",
        "    inputs = torch.cat([thetas_nn, phis_nn], dim=1)\n",
        "\n",
        "    loss_history = []\n",
        "\n",
        "\n",
        "    for run in range(num_realizations):\n",
        "\n",
        "        print(f\"\\n === Training run {run + 1}/{num_realizations} === Patches: {patch_idx}\")\n",
        "        model = CoreFlowPINN()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            optimizer.zero_grad()\n",
        "            L1, L2, _,_ = compute_loss(model, inputs, thetas_nn, phis_nn, Br_nn, dBrdt_nn, dBrdth_nn, dBrdph_nn)\n",
        "            L1_loss = (L1**2).mean()\n",
        "            L2_loss = (L2**2).mean()\n",
        "            Loss = L1_loss + Î» * L2_loss\n",
        "            Loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if epoch % 500 == 0:\n",
        "                print(f\"Epoch {epoch:4d} | L1 Loss: {L1_loss.item():12.6e} | L2 Loss: {L2_loss.item():12.6e} | Total Loss: {Loss.item():12.6e}\", flush=True)\n",
        "\n",
        "            # for graphs\n",
        "            loss_history.append(Loss)\n",
        "\n",
        "    #mean_loss_map = numpy.mean(loss_history, axis=0)\n",
        "    #loss_grid = mean_loss_map.reshape(len(thetas_bis), len(phis_bis))\n",
        "    patch_centers.append(((i1 + i2) // 2, (j1 + j2) // 2)) # for SV later\n",
        "\n",
        "\n",
        "print(\" Done computing for all patches.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert each tensor in loss_history to a detached NumPy array\n",
        "loss_history_np = [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in loss_history]\n",
        "\n",
        "# If loss_history_np is a 1D list of values, plot directly\n",
        "plt.loglog(loss_history_np)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qA6nnuFjtmJO"
      },
      "id": "qA6nnuFjtmJO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SV graph"
      ],
      "metadata": {
        "id": "9KgdKAF1qZLk"
      },
      "id": "9KgdKAF1qZLk"
    },
    {
      "cell_type": "code",
      "source": [
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import numpy as np\n",
        "\n",
        "def plot_sv_patch(dBrdt_patch, thetas_bis, phis_bis, patch_id=None):\n",
        "    # Convert from colatitude (theta) and longitude (phi) to lat/lon degrees\n",
        "    theta_grid, phi_grid = np.meshgrid(thetas_bis, phis_bis, indexing='ij')\n",
        "    lat_grid = 90 - np.rad2deg(theta_grid)   # colatitude to latitude\n",
        "    lon_grid = np.rad2deg(phi_grid)          # radians to degrees longitude\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 5))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.coastlines(resolution='110m')\n",
        "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
        "    ax.gridlines(draw_labels=True)\n",
        "\n",
        "    sc = ax.scatter(lon_grid, lat_grid, c=dBrdt_patch, cmap='seismic', s=20, transform=ccrs.PlateCarree())\n",
        "    cb = plt.colorbar(sc, orientation='vertical', shrink=0.7, pad=0.05)\n",
        "    cb.set_label(r'$\\partial B_r / \\partial t$ (SV)', fontsize=12)\n",
        "\n",
        "    if patch_id is not None:\n",
        "        ax.set_title(f'SV Patch {patch_id}')\n",
        "    else:\n",
        "        ax.set_title('SV Patch')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_sv_patch(dBrdt_patch, thetas_bis, phis_bis, patch_id=len(patch_centers)+1)\n"
      ],
      "metadata": {
        "id": "AH0b8kKYLuTh"
      },
      "id": "AH0b8kKYLuTh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "above: red for positive (increasing\n",
        "ðµ\n",
        "ð‘Ÿ\n",
        " ), blue for negative (decreasing\n",
        "ðµ\n",
        "ð‘Ÿ ).\n",
        "\n"
      ],
      "metadata": {
        "id": "f4uvMUmU35mf"
      },
      "id": "f4uvMUmU35mf"
    },
    {
      "cell_type": "code",
      "source": [
        "_, _, u_th, u_ph = compute_loss(model, inputs, thetas_nn, phis_nn, Br_nn, dBrdt_nn, dBrdth_nn, dBrdph_nn)\n",
        "\n",
        "# Used patch grid sizes, NOT the full global Br shape or else there is shape error\n",
        "patch_shape = (len(thetas_bis), len(phis_bis))\n",
        "\n",
        "u_th_map = u_th.reshape(patch_shape).detach().cpu().numpy()\n",
        "u_ph_map = u_ph.reshape(patch_shape).detach().cpu().numpy()\n"
      ],
      "metadata": {
        "id": "ngJ7R3UlLXt6"
      },
      "id": "ngJ7R3UlLXt6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cmocean\n",
        "import cartopy.crs as ccrs\n",
        "\n",
        "u_th_full = numpy.zeros((thetas.size, phis.size))\n",
        "u_th_full[i1:i2,j1:j2] = u_th_map\n",
        "\n",
        "thetas_bis_deg = numpy.rad2deg(thetas)\n",
        "phis_bis_deg = numpy.rad2deg(phis)\n",
        "\n",
        "latitudes = pygeo.convertThetasToLatitudes(thetas)\n",
        "longitudes = pygeo.convertPhisToLongitudes(phis)\n",
        "\n",
        "lat_grid, lon_grid = numpy.meshgrid(latitudes, longitudes, indexing=\"ij\")\n",
        "\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "\n",
        "# Set the projection to Hammer and add the axes\n",
        "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Aitoff())\n",
        "\n",
        "u_max = numpy.max(numpy.abs(u_th_full))\n",
        "\n",
        "# Use `pcolormesh` to project the data onto the map\n",
        "pcol = ax.pcolormesh(lon_grid, lat_grid, u_th_full, transform=ccrs.PlateCarree(), cmap=cmocean.cm.balance, vmin=-u_max, vmax=u_max)\n",
        "\n",
        "# Add coastlines for context\n",
        "ax.coastlines()\n",
        "\n",
        "plt.colorbar(pcol)"
      ],
      "metadata": {
        "id": "cPyqHgs7LanX"
      },
      "id": "cPyqHgs7LanX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
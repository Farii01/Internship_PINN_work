{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farii01/Internship_PINN_work/blob/main/June_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "WyE0odYT4N5r",
      "metadata": {
        "id": "WyE0odYT4N5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2bc3de-41b5-4298-c35b-d475fa61b90c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://gricad-gitlab.univ-grenoble-alpes.fr/claveaur/pygeotools.git\n",
            "  Cloning https://gricad-gitlab.univ-grenoble-alpes.fr/claveaur/pygeotools.git to /tmp/pip-req-build-hx3ic7xk\n",
            "  Running command git clone --filter=blob:none --quiet https://gricad-gitlab.univ-grenoble-alpes.fr/claveaur/pygeotools.git /tmp/pip-req-build-hx3ic7xk\n",
            "  Resolved https://gricad-gitlab.univ-grenoble-alpes.fr/claveaur/pygeotools.git to commit 87d5eab82dbae0c55a8d93113cd4ac6db38a0bf0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cartopy in /usr/local/lib/python3.11/dist-packages (from pygeodyntools==1.0.0) (0.24.1)\n",
            "Requirement already satisfied: cdflib in /usr/local/lib/python3.11/dist-packages (from pygeodyntools==1.0.0) (1.3.4)\n",
            "Requirement already satisfied: cmocean in /usr/local/lib/python3.11/dist-packages (from pygeodyntools==1.0.0) (4.0.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from pygeodyntools==1.0.0) (3.14.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pygeodyntools==1.0.0) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.11/dist-packages (from pygeodyntools==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.11/dist-packages (from pygeodyntools==1.0.0) (1.15.3)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.11/dist-packages (from cartopy->pygeodyntools==1.0.0) (2.1.1)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from cartopy->pygeodyntools==1.0.0) (24.2)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.11/dist-packages (from cartopy->pygeodyntools==1.0.0) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.11/dist-packages (from cartopy->pygeodyntools==1.0.0) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygeodyntools==1.0.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygeodyntools==1.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygeodyntools==1.0.0) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygeodyntools==1.0.0) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygeodyntools==1.0.0) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygeodyntools==1.0.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pygeodyntools==1.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=3.3.1->cartopy->pygeodyntools==1.0.0) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->pygeodyntools==1.0.0) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://gricad-gitlab.univ-grenoble-alpes.fr/claveaur/pygeotools.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "DrYzazJN4Pn6",
      "metadata": {
        "id": "DrYzazJN4Pn6"
      },
      "outputs": [],
      "source": [
        "import pygeotools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "53TdxT8P4SBC",
      "metadata": {
        "id": "53TdxT8P4SBC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "bf4d6aa2-17ce-4405-f8dd-1110a697026d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygeotools was initialized with `verbose=True`.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Unable to synchronously open object (bad object header version number)'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-718811504>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpygeo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygeotools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpygeotools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0;34m\"COVOBS-x2_400reals.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m pygeo.loadModel(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodelName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"COVOBS\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodelType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"covobs_hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pygeotools/pygeotools.py\u001b[0m in \u001b[0;36mloadModel\u001b[0;34m(self, modelName, modelType, modelPath, state)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mcase\u001b[0m \u001b[0;34m\"pygeodyn_hdf5\"\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mmodelQuantities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pygeodyn_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mcase\u001b[0m \u001b[0;34m\"chaos_hdf5\"\u001b[0m\u001b[0;34m:\u001b[0m      \u001b[0mmodelQuantities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_chaos_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mcase\u001b[0m \u001b[0;34m\"covobs_hdf5\"\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mmodelQuantities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_covobs_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mcase\u001b[0m \u001b[0;34m\"kalmag_hdf5\"\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mmodelQuantities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_kalmag_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mcase\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pygeotools/pygeotools.py\u001b[0m in \u001b[0;36mload_covobs_hdf5\u001b[0;34m(self, modelPath)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_q\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mmodelQuantities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_q\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_q\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodelQuantities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             raise TypeError(\"Accessing a group is done with bytes or str, \"\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Unable to synchronously open object (bad object header version number)'"
          ]
        }
      ],
      "source": [
        "model_path = \"/content/COVOBS-x2_400reals.hdf5\"\n",
        "\n",
        "pygeo = pygeotools.pygeotools()\n",
        "model_name=  \"COVOBS-x2_400reals.hdf5\"\n",
        "pygeo.loadModel(\n",
        "    modelName=\"COVOBS\",\n",
        "    modelType=\"covobs_hdf5\",\n",
        "    modelPath=\"COVOBS-x2_400reals.hdf5\"\n",
        ")\n",
        "\n",
        "\n",
        "pygeo.isLoaded(\"COVOBS\")  # Should return True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6397c23f",
      "metadata": {
        "id": "6397c23f"
      },
      "source": [
        "### Retrieving the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c703ff4",
      "metadata": {
        "id": "9c703ff4"
      },
      "outputs": [],
      "source": [
        "# Setting the grid\n",
        "pygeo.setGrid(\"1deg\")\n",
        "\n",
        "# Creating the context\n",
        "context = {\n",
        "    \"lmax\": 13,\n",
        "    \"r\": pygeo.constants[\"rCore\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbefdba0",
      "metadata": {
        "id": "cbefdba0"
      },
      "outputs": [],
      "source": [
        "# Computing the MF and SV\n",
        "MF = pygeo.addMeasure(\"COVOBS\", \"MF\", context)\n",
        "SV = pygeo.addMeasure(\"COVOBS\", \"SV\", context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec93eb1b",
      "metadata": {
        "id": "ec93eb1b"
      },
      "outputs": [],
      "source": [
        "# Retrieving the grid\n",
        "_, (thetas, phis) = pygeo.getCurrentGrid()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54866c66",
      "metadata": {
        "id": "54866c66"
      },
      "source": [
        "## Generating the patches for input in PINN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_EhA1-3KFOW_",
      "metadata": {
        "id": "_EhA1-3KFOW_"
      },
      "source": [
        "we cut the Earth into small square patches, train a separate neural network on each patch, then stitch the results together.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a797e596",
      "metadata": {
        "id": "a797e596"
      },
      "outputs": [],
      "source": [
        "def generate_patches(theta_size=20, phi_size=20, overlap=5):# 20 rows longitude, 20 cols latitude\n",
        "    patches = []\n",
        "# without overlap\n",
        "    dtheta = theta_size - overlap\n",
        "    dphi = phi_size - overlap\n",
        "\n",
        "#going from pole to pole (0 to 180 in colatitude) by stepping in 15° chunks (because dtheta = 15)\n",
        "    for i1 in range(0, 180 - theta_size + 1, dtheta):\n",
        "        i2 = i1 + theta_size\n",
        "        for j1 in range(0, 360 - phi_size + 1, dphi):\n",
        "            j2 = j1 + phi_size\n",
        "\n",
        "            patches.append((i1, i2, j1, j2))\n",
        "\n",
        "    return patches\n",
        "'''\n",
        "This loop creates a full list of (i1, i2, j1, j2) — patches of size 20°×20°, sliding across the whole globe, overlapping 5°.\n",
        "\n",
        "Each patch will be used to train a small PINN, then all will be stitched together into one global map.\n",
        "'''\n",
        "# How to use?\n",
        "patches = generate_patches(theta_size=20, phi_size=20, overlap=5)\n",
        "\n",
        "for i1, i2, j1, j2 in patches:\n",
        "    ... # For each patch, we have to solve the inverse problem"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Br = pygeo.selectFromMeasure(\"COVOBS\", MF, options={\"component\": \"r\", \"time\": 2020})\n",
        "dBrdt = pygeo.selectFromMeasure(\"COVOBS\", SV, options={\"component\": \"r\", \"time\": 2020})"
      ],
      "metadata": {
        "id": "aFpBjR6Tt9ND"
      },
      "id": "aFpBjR6Tt9ND",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "_yVqXaykwfGr"
      },
      "id": "_yVqXaykwfGr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The mean of Br across all realizations = Br_obs\n",
        "\n",
        "The standard deviation across realizations = σᵢ\n"
      ],
      "metadata": {
        "id": "JADwH8cLvrjP"
      },
      "id": "JADwH8cLvrjP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Br once for all patches\n",
        "Br_full = pygeo.selectFromMeasure(\n",
        "    modelName=\"COVOBS\",\n",
        "    measure=MF,\n",
        "    options={\n",
        "        \"components\": (0,),   # radial component Br\n",
        "        \"reals\": (0, 400)     # all 400 realizations\n",
        "    }\n",
        ")\n",
        "\n",
        "# Drop radius dimension (CMB)\n",
        "Br_all = Br_full[0, ...]  # shape: [180, 360, 400]\n",
        "\n",
        "# Loop over each patch\n",
        "for patch_idx, (i1, i2, j1, j2) in enumerate(patches, start=1):\n",
        "\n",
        "    if i1 < 10 or i2 > 170 or (i1 <= 90 <= i2):\n",
        "        continue  # skip equator and near-pole patches\n",
        "\n",
        "    if (i2 - i1) == 0 or (j2 - j1) == 0:\n",
        "        print(f\" Skipping empty patch: i1={i1}, i2={i2}, j1={j1}, j2={j2}\")\n",
        "        continue\n",
        "\n",
        "    if i2 > Br_all.shape[0] or j2 > Br_all.shape[1]:\n",
        "        print(f\" Skipping out-of-bound patch: i2={i2}, j2={j2}, Br_all shape={Br_all.shape}\")\n",
        "        continue\n",
        "\n",
        "    Br_patch_all = Br_all[i1:i2, j1:j2, :]  # shape: [ni, nj, 400]\n",
        "\n",
        "    if Br_patch_all.shape[0] == 0 or Br_patch_all.shape[1] == 0:\n",
        "        print(f\"Empty patch shape: {Br_patch_all.shape} for i=({i1},{i2}) j=({j1},{j2})\")\n",
        "        continue\n",
        "\n",
        "    # Mean and std across realizations\n",
        "    Br_obs_patch = torch.mean(torch.tensor(Br_patch_all), dim=-1, keepdim=True)\n",
        "    sigma_i_patch = torch.std(torch.tensor(Br_patch_all), dim=-1, keepdim=True)\n",
        "\n",
        "    # Flatten\n",
        "    Br_obs = Br_obs_patch.reshape(-1, 1)\n",
        "    sigma_i = sigma_i_patch.reshape(-1, 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "1e3h7zbFwapL"
      },
      "id": "1e3h7zbFwapL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "09e84ad3",
      "metadata": {
        "id": "09e84ad3"
      },
      "source": [
        "### Creating the NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20a3a9e",
      "metadata": {
        "id": "d20a3a9e"
      },
      "outputs": [],
      "source": [
        "node_inputs = 2\n",
        "node_outputs = 3\n",
        "\n",
        "node_layer = 64\n",
        "hidden_layers = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "120de866",
      "metadata": {
        "id": "120de866"
      },
      "outputs": [],
      "source": [
        "#  Defining the NN\n",
        "# For now, it has one hidden layer with 32 nodes\n",
        "# The activation functions are TANH\n",
        "class CoreFlowPINN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CoreFlowPINN, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        layers.append(nn.Linear(node_inputs, node_layer))\n",
        "        layers.append(nn.Tanh())\n",
        "\n",
        "        for _ in range(hidden_layers):\n",
        "            layers.append(nn.Linear(node_layer, node_layer))\n",
        "            layers.append(nn.Tanh())\n",
        "\n",
        "        layers.append(nn.Linear(node_layer, node_outputs))\n",
        "\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ONM5SM_4ct37",
      "metadata": {
        "id": "ONM5SM_4ct37"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of patches: {len(patches)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a604454",
      "metadata": {
        "id": "5a604454"
      },
      "source": [
        "### Adding the physics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7189ba3d",
      "metadata": {
        "id": "7189ba3d"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "We want to solve the radial induction equation at the CMB\n",
        "    dBr / dt + ∇h • (Uh Br) = 0\n",
        "\n",
        "with some quasi-geostrophic condition (meaning the flow will partly align along the axis of rotation, making columns-like flow)\n",
        "    ∇h • (Uh cos(θ)) = 0\n",
        "\n",
        "As the flow is incompressible, it is subject to ∇ • U = 0. As a result, it admits a unique toroidal-poloidal decomposition:\n",
        "    Uh = ∇ x (r T) + ∇ (r S)\n",
        "\n",
        "Thus, instead of directly predicting uθ and uφ, it appears clever to predict T and S as it already enforces the incompressibility condition.\n",
        "\n",
        "In spherical coordinates, one has\n",
        "    uθ = -(dT/dφ) / sin(θ) + dS/dθ\n",
        "    uφ = dT/dθ + (dS/dφ) / sin(θ)\n",
        "\"\"\"\n",
        "\n",
        "r = torch.tensor(pygeo.constants[\"rCore\"]) # placing ourselves at the CMB\n",
        "\n",
        "def compute_loss(model, inputs, thetas_nn, phis_nn, dBrdt_nn, Br_obs, sigma_i):\n",
        "\n",
        "\n",
        "\n",
        "    # Retrieving the predicted flow\n",
        "    u_pred = model(inputs)\n",
        "\n",
        "    # Retrieving the toroidal and poloidal components\n",
        "\n",
        "    T = u_pred[:, 0:1]\n",
        "    S = u_pred[:, 1:2]\n",
        "    Br_nn = u_pred[:, 2:3]\n",
        "\n",
        "\n",
        "    dBrdth_nn = torch.autograd.grad(Br_nn, thetas_nn, grad_outputs=torch.ones_like(Br_nn), create_graph=True)[0]\n",
        "    dBrdph_nn = torch.autograd.grad(Br_nn, phis_nn, grad_outputs=torch.ones_like(Br_nn), create_graph=True)[0]\n",
        "\n",
        "\n",
        "    # First derivatives of T and S\n",
        "    dT_dth = torch.autograd.grad(T, thetas_nn, grad_outputs=torch.ones_like(T), create_graph=True, retain_graph=True)[0]\n",
        "    dT_dph = torch.autograd.grad(T, phis_nn, grad_outputs=torch.ones_like(T), create_graph=True, retain_graph=True)[0]\n",
        "    dS_dth = torch.autograd.grad(S, thetas_nn, grad_outputs=torch.ones_like(S), create_graph=True, retain_graph=True)[0]\n",
        "    dS_dph = torch.autograd.grad(S, phis_nn, grad_outputs=torch.ones_like(S), create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    \"\"\"\n",
        "    Computing L1\n",
        "    \"\"\"\n",
        "    # Computing the L1² loss function\n",
        "    # L1² = || dBr / dt + ∇h • (Uh Br) ||²\n",
        "    # ∇h • (Uh Br) = (∇h • Uh) Br + Uh • (∇h Br)\n",
        "\n",
        "    sin_th = torch.sin(thetas_nn)\n",
        "    cos_th = torch.cos(thetas_nn)\n",
        "    tan_th = torch.tan(thetas_nn)\n",
        "\n",
        "    # We are defining u_th and u_ph with T and S\n",
        "    u_th = -dT_dph / sin_th + dS_dth\n",
        "    u_ph = dT_dth + dS_dph / sin_th\n",
        "\n",
        "    # Computing ∇h • Uh\n",
        "    u_th_sin_th = u_th * sin_th\n",
        "    d_u_th_sin_th_dth = torch.autograd.grad(u_th_sin_th, thetas_nn, grad_outputs=torch.ones_like(u_th_sin_th), create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    d_u_ph_dph = torch.autograd.grad(u_ph, phis_nn, grad_outputs=torch.ones_like(u_ph), create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    divH_uH = (1 / (r * sin_th)) * (d_u_th_sin_th_dth + d_u_ph_dph)\n",
        "    # divH_uH = u_th * tan_th / r\n",
        "\n",
        "    # Computing ∇h Br\n",
        "    # The derivatives are provided as they are not the NN variables but inputs\n",
        "    gradH_Br_th = (1 / r) * dBrdth_nn\n",
        "    gradH_Br_ph = (1 / (r * sin_th)) * dBrdph_nn\n",
        "\n",
        "    # Wrapping the induction equation\n",
        "    L1 = dBrdt_nn + Br_nn * divH_uH + u_th * gradH_Br_th + u_ph * gradH_Br_ph\n",
        "\n",
        "    L1_loss = (L1**2).mean()\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Computing L2\n",
        "    \"\"\"\n",
        "    L2 = divH_uH - u_th * tan_th / r\n",
        "    L2_loss = (L2**2).mean()\n",
        "    L2_loss_λ = λ * L2_loss\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Computing L3\n",
        "    \"\"\"\n",
        "    # L3 = (1/N) * Σ_i [ (Br_nn - Br_obs) / sigma_i ]²\n",
        "\n",
        "    Br_residual = Br_nn - Br_obs\n",
        "\n",
        "    L3 = torch.mean((Br_residual / sigma_i) ** 2)\n",
        "\n",
        "    L3_loss = (L3**2).mean()\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Computing L4 —  div(B) = 0\n",
        "    ∇h • Br = 1/(r sinθ) ∂(Br sinθ)/∂θ + 1/(r sinθ) ∂Br/∂φ\n",
        "    \"\"\"\n",
        "\n",
        "    Br_sin_th = Br_nn * sin_th\n",
        "\n",
        "    dBr_sin_th_dth = torch.autograd.grad(Br_sin_th, thetas_nn, grad_outputs=torch.ones_like(Br_sin_th), create_graph=True, retain_graph=True)[0]\n",
        "    dBr_dph = torch.autograd.grad(Br_nn, phis_nn, grad_outputs=torch.ones_like(Br_nn), create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    div_B = (1 / (r * sin_th)) * (dBr_sin_th_dth + dBr_dph)\n",
        "    L4 = torch.mean(div_B ** 2)\n",
        "    μ = 0\n",
        "\n",
        "\n",
        "    L4_Loss= μ * L4\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return L1_loss, L2_loss_λ, L3_loss, L4_Loss, u_th, u_ph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Br_obs.shape\n"
      ],
      "metadata": {
        "id": "QLDGDZj0xN_D"
      },
      "id": "QLDGDZj0xN_D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c42f4fa3",
      "metadata": {
        "id": "c42f4fa3"
      },
      "outputs": [],
      "source": [
        "# I moved everything to the training loop so that for each patch in every iteration, the model receives the correct,\n",
        "# patch-specific input like thetas_nn, phis_nn, Br_nn, dBrdt_nn, dBrdth_nn, dBrdph_nn\n",
        "\n",
        "\n",
        "\n",
        "# Training over all patches\n",
        "num_realizations = 1 # 5 time on each patch\n",
        "epochs = 1000\n",
        "λ = 1000\n",
        "\n",
        "patch_centers=[]\n",
        "\n",
        "\n",
        "print(f\"Number of times each patch will run: {num_realizations}\")\n",
        "print(f\"Number of epochs: {epochs}\")\n",
        "\n",
        "\n",
        "'''\n",
        "# for all patches\n",
        "for i1, i2, j1, j2 in patches:\n",
        "    if i1 < 10 or i2 > 170 or (i1 <= 90 <= i2):\n",
        "        continue  # skip poles and equator\n",
        "\n",
        "'''\n",
        "\n",
        "# for less time consumption, I am using 50 patches\n",
        "test_patches = patches[ :24 ] # you can slice it if u want less, that is why i created a seperate variable\n",
        "\n",
        "print(f\"Number of patches: {len(patches)} but we will consider : {len(test_patches)}\")\n",
        "\n",
        "for patch_idx, (i1, i2, j1, j2) in enumerate(test_patches, start=1):\n",
        "    # Skip poles and equator patches if needed\n",
        "    if i1 < 10 or i2 > 170 or (i1 <= 90 <= i2):\n",
        "      continue\n",
        "\n",
        "\n",
        "    print(f\"Processing from patch {patch_idx} Since the ones before were either equator or pole\") # To know when it is starting and what is getting out of calculation\n",
        "\n",
        "    #slice all Br and inputs\n",
        "    Br_patch = Br[i1:i2, j1:j2, ...]\n",
        "    dBrdt_patch = dBrdt[i1:i2, j1:j2, ...]\n",
        "\n",
        "    #differential or br and sv w.r.t. phi and theta\n",
        "    dBrdth = numpy.gradient(Br, thetas, axis=0)[i1:i2, j1:j2, ...]\n",
        "    dBrdph = numpy.gradient(Br, phis, axis=1)[i1:i2, j1:j2, ...]\n",
        "\n",
        "    thetas_bis = thetas[i1:i2]\n",
        "    phis_bis = phis[j1:j2]\n",
        "\n",
        "    thetas_grid, phis_grid = numpy.meshgrid(thetas_bis, phis_bis, indexing=\"ij\")\n",
        "    thetas_flat = thetas_grid.flatten()\n",
        "    phis_flat = phis_grid.flatten()\n",
        "\n",
        "    thetas_nn = torch.tensor(thetas_flat[:, None], dtype=torch.float32, requires_grad=True)\n",
        "    phis_nn = torch.tensor(phis_flat[:, None], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "\n",
        "    dBrdt_nn = torch.tensor(dBrdt_patch.flatten()[:, None], dtype=torch.float32)\n",
        "    dBrdth_nn = torch.tensor(dBrdth.flatten()[:, None], dtype=torch.float32)\n",
        "    dBrdph_nn = torch.tensor(dBrdph.flatten()[:, None], dtype=torch.float32)\n",
        "\n",
        "    inputs = torch.cat([thetas_nn, phis_nn], dim=1)\n",
        "\n",
        "    loss_history = []\n",
        "    L1_history = []\n",
        "    L2_history = []\n",
        "\n",
        "\n",
        "\n",
        "    for run in range(num_realizations):\n",
        "\n",
        "        print(f\"\\n === Training run {run + 1}/{num_realizations} === Patches: {patch_idx}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            final_layer = model.net[-1]\n",
        "            final_layer.weight += 20  # or try different values like 10, 30, etc.\n",
        "            final_layer.bias.zero_()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Use zeros for dBr/dt at epoch 0\n",
        "            if epoch == 0:\n",
        "                dBrdt_nn_zero = torch.zeros_like(dBrdt_nn)\n",
        "                L1_loss, L2_loss_λ, L3_loss, L4_loss, _, _ = compute_loss(model, inputs, thetas_nn, phis_nn, dBrdt_nn_zero, Br_obs, sigma_i)\n",
        "            else:\n",
        "                L1_loss, L2_loss_λ, L3_loss, L4_loss, _, _ = compute_loss(model, inputs, thetas_nn, phis_nn, dBrdt_nn, Br_obs, sigma_i)\n",
        "\n",
        "            Loss = L1_loss + L2_loss_λ\n",
        "            Loss.backward()\n",
        "\n",
        "            if epoch == 0:\n",
        "                with torch.no_grad():\n",
        "                    final_layer = model.net[-1]\n",
        "                    final_layer.weight += 1e-4 * torch.randn_like(final_layer.weight)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            if epoch % 5 == 0:\n",
        "                print(f\"Epoch {epoch:4d} | L1 Loss: {L1_loss.item():12.6e} | L2 Loss: {L2_loss_λ.item():12.6e} | Total Loss: {Loss.item():12.6e}\", flush=True)\n",
        "\n",
        "            # for graphs\n",
        "            loss_history.append(Loss)\n",
        "            L1_history.append(L1_loss)\n",
        "            L2_history.append(L2_loss_λ)\n",
        "\n",
        "    #mean_loss_map = numpy.mean(loss_history, axis=0)\n",
        "    #loss_grid = mean_loss_map.reshape(len(thetas_bis), len(phis_bis))\n",
        "    patch_centers.append(((i1 + i2) // 2, (j1 + j2) // 2)) # for SV later\n",
        "\n",
        "\n",
        "print(\" Done computing for all patches.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert each tensor in loss_history to a detached NumPy array\n",
        "loss_history_np = [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in loss_history]\n",
        "\n",
        "# If loss_history_np is a 1D list of values, plot directly\n",
        "plt.loglog(loss_history_np)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qA6nnuFjtmJO"
      },
      "id": "qA6nnuFjtmJO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Convert each tensor in loss_history to a detached NumPy array\n",
        "loss_history_np1 = [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in L1_history]\n",
        "loss_history_np2 = [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in L2_history]\n",
        "\n",
        "# Plot both on a log-log scale with different colors and labels\n",
        "plt.loglog(loss_history_np1, label='L1 Loss', color='blue')\n",
        "plt.loglog(loss_history_np2, label='L2 Loss', color='orange')\n",
        "\n",
        "# Add legend and display\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss History (Log-Log Plot)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pnPhQCPp__EL"
      },
      "id": "pnPhQCPp__EL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SV graph"
      ],
      "metadata": {
        "id": "9KgdKAF1qZLk"
      },
      "id": "9KgdKAF1qZLk"
    },
    {
      "cell_type": "code",
      "source": [
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import numpy as np\n",
        "\n",
        "def plot_sv_patch(dBrdt_patch, thetas_bis, phis_bis, patch_id=None):\n",
        "    # Convert from colatitude (theta) and longitude (phi) to lat/lon degrees\n",
        "    theta_grid, phi_grid = np.meshgrid(thetas_bis, phis_bis, indexing='ij')\n",
        "    lat_grid = 90 - np.rad2deg(theta_grid)   # colatitude to latitude\n",
        "    lon_grid = np.rad2deg(phi_grid)          # radians to degrees longitude\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 5))\n",
        "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "    ax.coastlines(resolution='110m')\n",
        "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
        "    ax.gridlines(draw_labels=True)\n",
        "\n",
        "    sc = ax.scatter(lon_grid, lat_grid, c=dBrdt_patch, cmap='seismic', s=20, transform=ccrs.PlateCarree())\n",
        "    cb = plt.colorbar(sc, orientation='vertical', shrink=0.7, pad=0.05)\n",
        "    cb.set_label(r'$\\partial B_r / \\partial t$ (SV)', fontsize=12)\n",
        "\n",
        "    if patch_id is not None:\n",
        "        ax.set_title(f'SV Patch {patch_id}')\n",
        "    else:\n",
        "        ax.set_title('SV Patch')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_sv_patch(dBrdt_patch, thetas_bis, phis_bis, patch_id=len(patch_centers)+1)\n"
      ],
      "metadata": {
        "id": "AH0b8kKYLuTh"
      },
      "id": "AH0b8kKYLuTh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "above: red for positive (increasing\n",
        "𝐵\n",
        "𝑟\n",
        " ), blue for negative (decreasing\n",
        "𝐵\n",
        "𝑟 ).\n",
        "\n"
      ],
      "metadata": {
        "id": "f4uvMUmU35mf"
      },
      "id": "f4uvMUmU35mf"
    },
    {
      "cell_type": "code",
      "source": [
        "_,_,_,_, u_th, u_ph = compute_loss(model, inputs, thetas_nn, phis_nn, dBrdt_nn_zero, Br_obs, sigma_i)\n",
        "# Used patch grid sizes, NOT the full global Br shape or else there is shape error\n",
        "patch_shape = (len(thetas_bis), len(phis_bis))\n",
        "\n",
        "u_th_map = u_th.reshape(patch_shape).detach().cpu().numpy()\n",
        "u_ph_map = u_ph.reshape(patch_shape).detach().cpu().numpy()\n"
      ],
      "metadata": {
        "id": "ngJ7R3UlLXt6"
      },
      "id": "ngJ7R3UlLXt6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cmocean\n",
        "import cartopy.crs as ccrs\n",
        "\n",
        "u_th_full = numpy.zeros((thetas.size, phis.size))\n",
        "u_th_full[i1:i2,j1:j2] = u_th_map\n",
        "\n",
        "thetas_bis_deg = numpy.rad2deg(thetas)\n",
        "phis_bis_deg = numpy.rad2deg(phis)\n",
        "\n",
        "latitudes = pygeo.convertThetasToLatitudes(thetas)\n",
        "longitudes = pygeo.convertPhisToLongitudes(phis)\n",
        "\n",
        "lat_grid, lon_grid = numpy.meshgrid(latitudes, longitudes, indexing=\"ij\")\n",
        "\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "\n",
        "# Set the projection to Hammer and add the axes\n",
        "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Aitoff())\n",
        "\n",
        "u_max = numpy.max(numpy.abs(u_th_full))\n",
        "\n",
        "# Use `pcolormesh` to project the data onto the map\n",
        "pcol = ax.pcolormesh(lon_grid, lat_grid, u_th_full, transform=ccrs.PlateCarree(), cmap=cmocean.cm.balance, vmin=-u_max, vmax=u_max)\n",
        "\n",
        "# Add coastlines for context\n",
        "ax.coastlines()\n",
        "\n",
        "plt.colorbar(pcol)"
      ],
      "metadata": {
        "id": "cPyqHgs7LanX"
      },
      "id": "cPyqHgs7LanX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}